import sys
import os
import glob
import torch
import numpy as np
import librosa
import argparse


# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from src.lsm import AION_LSM_Network
from src.config import LSM_N_NEURONS, OBS_SHAPE, AUDIO_SR, HOP_LENGTH, WEIGHTS_PATH, DEVICE

def train_gpu(dataset_path, limit=None):
    print(f"ğŸš€ å¯åŠ¨ GPU è®­ç»ƒ (Device: {DEVICE})")
    print(f"   æ•°æ®é›†: {dataset_path}")
    print(f"   ç¥ç»å…ƒ: {LSM_N_NEURONS}")
    
    # 1. åˆå§‹åŒ–æ¨¡å‹
    lsm = AION_LSM_Network(device=DEVICE)
    
    # Ridge Regression ç´¯ç§¯çŸ©é˜µ (GPU Tensor)
    # S^T * S (NxN)
    STS = torch.zeros(LSM_N_NEURONS, LSM_N_NEURONS, device=DEVICE)
    # S^T * Y (NxOut)
    STY = torch.zeros(LSM_N_NEURONS, OBS_SHAPE, device=DEVICE)
    
    frames_count = 0
    
    # 2. åŠ è½½æ–‡ä»¶
    wav_files = glob.glob(os.path.join(dataset_path, "**/*.wav"), recursive=True)
    if not wav_files:
        print("âŒ æœªæ‰¾åˆ° WAV æ–‡ä»¶")
        return
        
    if limit:
        wav_files = wav_files[:limit]
        
    print(f"ğŸ“‚ å¾…å¤„ç†æ–‡ä»¶æ•°: {len(wav_files)}")
    
    # 3. å¤„ç†å¾ªç¯
    try:
        total = len(wav_files)
        for i, wav_path in enumerate(wav_files):
            if i % 10 == 0: print(f"æ­£åœ¨å¤„ç† {i}/{total}...")
            # åŠ è½½éŸ³é¢‘
            y, sr = librosa.load(wav_path, sr=AUDIO_SR)
            mel = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=OBS_SHAPE, hop_length=HOP_LENGTH, n_fft=HOP_LENGTH*2)
            mel_db = librosa.power_to_db(mel, ref=1.0)
            
            # åºåˆ—å¤„ç†ï¼šä¿ç•™æ—¶åºç»“æ„ (T, F)
            mel_seq = (mel_db.T + 80.0)/80.0
            mel_seq = np.clip(mel_seq, 0, 1) # (T, 64)
            
            mel_tensor = torch.tensor(mel_seq, dtype=torch.float32, device=DEVICE)
            
            lsm.reset()
            
            # æ”¶é›†çŠ¶æ€ (Inputs) å’Œ ç›®æ ‡ (Targets)
            # è¾“å…¥: Mel[t]
            # ç›®æ ‡: Mel[t+1] (é¢„æµ‹ä¸‹ä¸€å¸§)
            inputs = mel_tensor[:-1]
            targets = mel_tensor[1:]
            
            # é€å¸§è¿è¡Œä»¿çœŸ
            spikes_list = []
            
            # è‡ªå®šä¹‰å‰å‘å¾ªç¯ä»¥ç»´æŒçŠ¶æ€
            for t in range(len(inputs)):
                # è¾“å…¥éœ€è¦æ˜¯ (1, In) ç»´åº¦
                s = lsm.forward(inputs[t].unsqueeze(0)) # (1, N)
                spikes_list.append(s)
                
            S = torch.cat(spikes_list, dim=0) # (T-1, N)
            Y = targets # (T-1, Out)
            
            # ç´¯ç§¯ç›¸å…³æ€§çŸ©é˜µ (Ridge Regression)
            # STS += S.T @ S
            STS += torch.mm(S.T, S)
            # STY += S.T @ Y
            STY += torch.mm(S.T, Y)
            
            frames_count += len(S)
            pass
            
    except KeyboardInterrupt:
        print("\nğŸ›‘ åœæ­¢è®­ç»ƒ...")
        
    # 4. æ±‚è§£æƒé‡
    if frames_count > 0:
        print("ğŸ—ï¸ æ­£åœ¨æ±‚è§£æƒé‡...")
        # å²­å›å½’ (Ridge Regularization)
        lambda_reg = 10.0
        I = torch.eye(LSM_N_NEURONS, device=DEVICE)
        
        A = STS + lambda_reg * I
        B = STY
        
        # Torch æ±‚è§£: A * W = B

        # torch.linalg.solve assumes A is square batch.
        try:
            W_out = torch.linalg.solve(A, B)
            
            # Save
            torch.save(W_out, WEIGHTS_PATH)
            print(f"âœ… æƒé‡å·²ä¿å­˜è‡³: {WEIGHTS_PATH}")
            print(f"   Max Weight: {torch.max(torch.abs(W_out)):.4f}")
            
        except RuntimeError as e:
            print(f"âŒ æ±‚è§£å¤±è´¥: {e}")
            
if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--data", type=str, required=True)
    parser.add_argument("--limit", type=int, default=None)
    args = parser.parse_args()
    
    train_gpu(args.data, args.limit)
